# GW MSBA Practicum - MITRE - Opioid Research

<hr>

**Data Repository:**

[AWS S3 Bucket](https://s3.console.aws.amazon.com/s3/buckets/practicum-mitre/?region=us-east-1&tab=overview)

<hr>

**Python Notebooks:**


[Medicare Part D - Cleaning](https://github.com/martimsilva/practicum_mitre/blob/master/Medicare%20Part%20D%20Opioid%20Prescriber%20Dataset%20Year%202015-2017.ipynb)

(Report section 4.1, 6.1, 7.1)

[Medicare - Cleaning 1.0](https://github.com/martimsilva/practicum_mitre/blob/master/Cleaning%20Medicare%20Dataset.ipynb)

This code cleans the Medicare Utilization and Payment data and makes three csvs, one for 2015, 2016, and 2017 respectively. (Report section 4.2, 6.2, 7.2)

[Medicaid - Cleaning](https://github.com/martimsilva/practicum_mitre/blob/master/Medicaid_Cleaning.ipynb)

This dataset is the data cleaning process for the 2015-2017 Medicaid data. 
(Report section 4.5, 6.3, 7.3)

[DEA - Cleaning](https://github.com/martimsilva/practicum_mitre/blob/master/dea-sample.ipynb)

This dataset is a data cleaning process on a sample of DEA data. 
(Report section 4.6, 6.4, 7.4)

[DEA - Spark](https://github.com/martimsilva/practicum_mitre/blob/master/dea_spark_code_filtering.txt)

(Report section 4.6, 6.4, 7.4)

[Mortality Dataset - Model](https://github.com/martimsilva/practicum_mitre/blob/master/Mort2017_EDA_Final.ipynb)

We mainly built our prediction models based on the mortality dataset (mort2017.csv). This jupyter notebook contains the entire process of data cleanning, exploratory data analysis, and all the models we have applied to make the future prediciton. (Report section 4.7, 6.5, 7.5~7.6)

<hr>

**R Markdown**

[Medicare - Cleaning 2.0](https://github.com/martimsilva/practicum_mitre/blob/master/Cleaning%20Medicare.Rmd)

This code combines the 2015, 2016, and 2017 Medicare Utilization csvs created by the python notebook into one combined csv. (Report section 4.2, 6.2, 7.2)

<hr>

[Download Packaged Code](https://github.com/martimsilva/practicum_mitre/archive/master.zip)
